{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unsuccessful_Faster_RCNN.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "FIqnjbWYsuQw",
        "2FKFq8RXs6bs",
        "MFyCeiBb9BbS"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SibaIssa/Surgical-Instrument-tracking/blob/main/Unsuccessful_Faster_RCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhzxsJb3dpWq"
      },
      "source": [
        "## Configs and Hyperparameters\n",
        "\n",
        "Support a variety of models, you can find more pretrained model from [Tensorflow detection model zoo: COCO-trained models](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models), as well as their pipline config files in [object_detection/samples/configs/](https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnNXNQCjdniL"
      },
      "source": [
        "\n",
        "# If you forked the repository, you can replace the link.\n",
        "repo_url = 'https://github.com/Kshitijpawar/License_Plate_Detection'\n",
        "\n",
        "# Number of training steps.\n",
        "num_steps = 1000  # 200000\n",
        "\n",
        "# Number of evaluation steps.\n",
        "num_eval_steps = 50\n",
        "\n",
        "MODELS_CONFIG = {\n",
        "    'ssd_mobilenet_v2': {\n",
        "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
        "        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'faster_rcnn_inception_v2': {\n",
        "        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n",
        "        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'rfcn_resnet101': {\n",
        "        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n",
        "        'pipeline_file': 'rfcn_resnet101_pets.config',\n",
        "        'batch_size': 8\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "# Select a model from `MODELS_CONFIG`.\n",
        "selected_model = 'ssd_mobilenet_v2'\n",
        "\n",
        "# Name of the object detection model to use.\n",
        "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
        "\n",
        "# Name of the pipeline file in tensorflow object detection API.\n",
        "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
        "\n",
        "# Training batch size fits in Colabe's Tesla K80 GPU memory for selected model.\n",
        "batch_size = MODELS_CONFIG[selected_model]['batch_size']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4V-XE6kbkc1"
      },
      "source": [
        "## Clone the `tensorflow-object-detection` repository or your fork."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxc3DmvLQF3z",
        "outputId": "5f8dee1e-731e-42d5-9cc2-7aaa4f7debc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "\n",
        "%cd /content\n",
        "\n",
        "repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n",
        "\n",
        "!git clone {repo_url}\n",
        "%cd {repo_dir_path}\n",
        "!git pull"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'tensorflow-object-detection-faster-rcnn'...\n",
            "remote: Enumerating objects: 885, done.\u001b[K\n",
            "remote: Total 885 (delta 0), reused 0 (delta 0), pack-reused 885\u001b[K\n",
            "Receiving objects: 100% (885/885), 24.83 MiB | 26.97 MiB/s, done.\n",
            "Resolving deltas: 100% (428/428), done.\n",
            "/content/tensorflow-object-detection-faster-rcnn\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI8__uNS8-ns"
      },
      "source": [
        "## Install required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecpHEnka8Kix",
        "outputId": "9e7bf839-d50f-4701-d16f-85fcc819be42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd /content\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "\n",
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
        "\n",
        "!pip install -q pycocotools\n",
        "\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
        "\n",
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Selecting previously unselected package python-bs4.\n",
            "(Reading database ... 155320 files and directories currently installed.)\n",
            "Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n",
            "Unpacking python-bs4 (4.6.0-1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-chardet.\n",
            "Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n",
            "Unpacking python-chardet (3.0.4-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-webencodings.\n",
            "Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n",
            "Unpacking python-webencodings (0.5-2) ...\n",
            "Selecting previously unselected package python-html5lib.\n",
            "Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n",
            "Unpacking python-html5lib (0.999999999-1) ...\n",
            "Selecting previously unselected package python-lxml:amd64.\n",
            "Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.6_amd64.deb ...\n",
            "Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.6) ...\n",
            "Selecting previously unselected package python-olefile.\n",
            "Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n",
            "Unpacking python-olefile (0.45.1-1) ...\n",
            "Selecting previously unselected package python-pil:amd64.\n",
            "Preparing to unpack .../8-python-pil_5.1.0-1ubuntu0.7_amd64.deb ...\n",
            "Unpacking python-pil:amd64 (5.1.0-1ubuntu0.7) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python-bs4 (4.6.0-1) ...\n",
            "Setting up python-lxml:amd64 (4.2.1-1ubuntu0.6) ...\n",
            "Setting up python-olefile (0.45.1-1) ...\n",
            "Setting up python-pil:amd64 (5.1.0-1ubuntu0.7) ...\n",
            "Setting up python-webencodings (0.5-2) ...\n",
            "Setting up python-chardet (3.0.4-1) ...\n",
            "Setting up python-html5lib (0.999999999-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "/content/models/research\n",
            "Traceback (most recent call last):\n",
            "  File \"object_detection/builders/model_builder_test.py\", line 21, in <module>\n",
            "    from object_detection.builders import model_builder\n",
            "  File \"/content/models/research/object_detection/builders/model_builder.py\", line 37, in <module>\n",
            "    from object_detection.meta_architectures import deepmac_meta_arch\n",
            "  File \"/content/models/research/object_detection/meta_architectures/deepmac_meta_arch.py\", line 28, in <module>\n",
            "    import tensorflow_io as tfio  # pylint:disable=g-import-not-at-top\n",
            "ModuleNotFoundError: No module named 'tensorflow_io'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-k7uGThXlny"
      },
      "source": [
        "## Prepare `tfrecord` files\n",
        "\n",
        "Roboflow automatically creates our TFRecord and label_map files that we need!\n",
        "\n",
        "**Generating your own TFRecords the only step you need to change for your own custom dataset.**\n",
        "\n",
        "Because we need one TFRecord file for our training data, and one TFRecord file for our test data, we'll create two separate datasets in Roboflow and generate one set of TFRecords for each.\n",
        "\n",
        "To create a dataset in Roboflow and generate TFRecords, follow [this step-by-step guide](https://blog.roboflow.ai/getting-started-with-roboflow/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNfIPc5yxDOv",
        "outputId": "071a4374-4a5c-4055-95aa-fc2e35245ff6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd /content/tensorflow-object-detection-faster-rcnn/data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/tensorflow-object-detection-faster-rcnn/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yb_FMcfnSbRZ",
        "outputId": "cd186162-a533-450f-d5a5-ffa6f6bb6f07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# UPDATE THIS LINK - get our data from Roboflow\n",
        "!curl -L https://app.roboflow.ai/ds/Db1uzDZXPU?key=8nBtEdlqp9 > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100    68  100    68    0     0    209      0 --:--:-- --:--:-- --:--:--   210\n",
            "100   891  100   891    0     0   1197      0 --:--:-- --:--:-- --:--:--  4689\n",
            "100  324M  100  324M    0     0   126M      0  0:00:02  0:00:02 --:--:--  189M\n",
            "Archive:  roboflow.zip\n",
            " extracting: README.dataset.txt      \n",
            " extracting: README.roboflow.txt     \n",
            "   creating: test/\n",
            " extracting: test/instrument.tfrecord  \n",
            " extracting: test/instrument_label_map.pbtxt  \n",
            "   creating: train/\n",
            " extracting: train/instrument.tfrecord  \n",
            " extracting: train/instrument_label_map.pbtxt  \n",
            "   creating: valid/\n",
            " extracting: valid/instrument.tfrecord  \n",
            " extracting: valid/instrument_label_map.pbtxt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7T58u1YP9sUW",
        "outputId": "2cc7678b-b46a-4eba-bbc5-6e2e61f33ba9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FYI.txt  README.dataset.txt  README.roboflow.txt  \u001b[0m\u001b[01;34mtest\u001b[0m/  \u001b[01;34mtrain\u001b[0m/  \u001b[01;34mvalid\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5qhOGaTTFsq",
        "outputId": "33384616-eb24-4b8a-8d04-c111d5ca7e12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# check out what we have\n",
        "%cd train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/tensorflow-object-detection-faster-rcnn/data/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_1SbvmATHk-",
        "outputId": "a0857f41-1d59-4cf0-b962-eaa17e224bdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# list contents\n",
        "%ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "instrument_label_map.pbtxt  instrument.tfrecord\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKnnSSBu_XXF",
        "outputId": "1ef2cab2-75f9-4d4e-8bc5-6367b691e2b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "instrument_label_map.pbtxt  instrument.tfrecord\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgd-fzAIkZlV"
      },
      "source": [
        "# NOTE: Update these TFRecord names from \"cells\" and \"cells_label_map\" to your files!\n",
        "test_record_fname = '/content/tensorflow-object-detection-faster-rcnn/data/valid/instrument.tfrecord'\n",
        "train_record_fname = '/content/tensorflow-object-detection-faster-rcnn/data/train/instrument.tfrecord'\n",
        "label_map_pbtxt_fname = '/content/tensorflow-object-detection-faster-rcnn/data/train/instrument_label_map.pbtxt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCNYAaC7w6N8"
      },
      "source": [
        "## Download base model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orDCj6ihgUMR",
        "outputId": "cb5fa14f-5868-4b1b-ff73-8cea60da822d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd /content/models/research\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import urllib.request\n",
        "import tarfile\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "DEST_DIR = '/content/models/research/pretrained_model'\n",
        "\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "    shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGhvAObeiIix",
        "outputId": "f1f72b05-2c58-41df-87e6-ce7f4d8ad7de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!echo {DEST_DIR}\n",
        "!ls -alh {DEST_DIR}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research/pretrained_model\n",
            "total 111M\n",
            "drwxr-xr-x  3 345018 5000 4.0K Feb  1  2018 .\n",
            "drwxr-xr-x 23 root   root 4.0K Mar  7 23:58 ..\n",
            "-rw-r--r--  1 345018 5000   77 Feb  1  2018 checkpoint\n",
            "-rw-r--r--  1 345018 5000  55M Feb  1  2018 frozen_inference_graph.pb\n",
            "-rw-r--r--  1 345018 5000  51M Feb  1  2018 model.ckpt.data-00000-of-00001\n",
            "-rw-r--r--  1 345018 5000  16K Feb  1  2018 model.ckpt.index\n",
            "-rw-r--r--  1 345018 5000 5.5M Feb  1  2018 model.ckpt.meta\n",
            "-rw-r--r--  1 345018 5000 3.2K Feb  1  2018 pipeline.config\n",
            "drwxr-xr-x  3 345018 5000 4.0K Feb  1  2018 saved_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHnxlfRznPP3",
        "outputId": "ef282e4f-b042-483d-b6f0-2b6af1991c85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n",
        "fine_tune_checkpoint"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/models/research/pretrained_model/model.ckpt'"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvwtHlLOeRJD"
      },
      "source": [
        "## Configuring a Training Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIhw7IdpLuiU"
      },
      "source": [
        "import os\n",
        "pipeline_fname = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n",
        "\n",
        "assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG1nCNpUXcRU"
      },
      "source": [
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjtCbLF2i0wI"
      },
      "source": [
        "import re\n",
        "\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open(pipeline_fname, 'w') as f:\n",
        "    \n",
        "    # fine_tune_checkpoint\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "    \n",
        "    # tfrecord files train and test.\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
        "\n",
        "    # label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Set training batch_size.\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "    \n",
        "    # Set number of classes num_classes.\n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "    f.write(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH0MEEanocn6",
        "outputId": "c41705ce-d72d-4ecd-f949-0e66efa5b069",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!cat {pipeline_fname}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Faster R-CNN with Inception v2, configured for Oxford-IIIT Pets Dataset.\n",
            "# Users should configure the fine_tune_checkpoint field in the train config as\n",
            "# well as the label_map_path and input_path fields in the train_input_reader and\n",
            "# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n",
            "# should be configured.\n",
            "\n",
            "model {\n",
            "  faster_rcnn {\n",
            "    num_classes: 3\n",
            "    image_resizer {\n",
            "      keep_aspect_ratio_resizer {\n",
            "        min_dimension: 600\n",
            "        max_dimension: 1024\n",
            "      }\n",
            "    }\n",
            "    feature_extractor {\n",
            "      type: 'faster_rcnn_inception_v2'\n",
            "      first_stage_features_stride: 16\n",
            "    }\n",
            "    first_stage_anchor_generator {\n",
            "      grid_anchor_generator {\n",
            "        scales: [0.25, 0.5, 1.0, 2.0]\n",
            "        aspect_ratios: [0.5, 1.0, 2.0]\n",
            "        height_stride: 16\n",
            "        width_stride: 16\n",
            "      }\n",
            "    }\n",
            "    first_stage_box_predictor_conv_hyperparams {\n",
            "      op: CONV\n",
            "      regularizer {\n",
            "        l2_regularizer {\n",
            "          weight: 0.0\n",
            "        }\n",
            "      }\n",
            "      initializer {\n",
            "        truncated_normal_initializer {\n",
            "          stddev: 0.01\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    first_stage_nms_score_threshold: 0.0\n",
            "    first_stage_nms_iou_threshold: 0.7\n",
            "    first_stage_max_proposals: 300\n",
            "    first_stage_localization_loss_weight: 2.0\n",
            "    first_stage_objectness_loss_weight: 1.0\n",
            "    initial_crop_size: 14\n",
            "    maxpool_kernel_size: 2\n",
            "    maxpool_stride: 2\n",
            "    second_stage_box_predictor {\n",
            "      mask_rcnn_box_predictor {\n",
            "        use_dropout: false\n",
            "        dropout_keep_probability: 1.0\n",
            "        fc_hyperparams {\n",
            "          op: FC\n",
            "          regularizer {\n",
            "            l2_regularizer {\n",
            "              weight: 0.0\n",
            "            }\n",
            "          }\n",
            "          initializer {\n",
            "            variance_scaling_initializer {\n",
            "              factor: 1.0\n",
            "              uniform: true\n",
            "              mode: FAN_AVG\n",
            "            }\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    second_stage_post_processing {\n",
            "      batch_non_max_suppression {\n",
            "        score_threshold: 0.0\n",
            "        iou_threshold: 0.6\n",
            "        max_detections_per_class: 100\n",
            "        max_total_detections: 300\n",
            "      }\n",
            "      score_converter: SOFTMAX\n",
            "    }\n",
            "    second_stage_localization_loss_weight: 2.0\n",
            "    second_stage_classification_loss_weight: 1.0\n",
            "  }\n",
            "}\n",
            "\n",
            "train_config: {\n",
            "  batch_size: 12\n",
            "  optimizer {\n",
            "    momentum_optimizer: {\n",
            "      learning_rate: {\n",
            "        manual_step_learning_rate {\n",
            "          initial_learning_rate: 0.0002\n",
            "          schedule {\n",
            "            step: 900000\n",
            "            learning_rate: .00002\n",
            "          }\n",
            "          schedule {\n",
            "            step: 1200000\n",
            "            learning_rate: .000002\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "      momentum_optimizer_value: 0.9\n",
            "    }\n",
            "    use_moving_average: false\n",
            "  }\n",
            "  gradient_clipping_by_norm: 10.0\n",
            "  fine_tune_checkpoint: \"/content/models/research/pretrained_model/model.ckpt\"\n",
            "  from_detection_checkpoint: true\n",
            "  load_all_detection_checkpoint_vars: true\n",
            "  # Note: The below line limits the training process to 200K steps, which we\n",
            "  # empirically found to be sufficient enough to train the pets dataset. This\n",
            "  # effectively bypasses the learning rate schedule (the learning rate will\n",
            "  # never decay). Remove the below line to train indefinitely.\n",
            "  num_steps: 10000\n",
            "  data_augmentation_options {\n",
            "    random_horizontal_flip {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "train_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/tensorflow-object-detection-faster-rcnn/data/train/instrument.tfrecord\"\n",
            "  }\n",
            "  label_map_path: \"/content/tensorflow-object-detection-faster-rcnn/data/train/instrument_label_map.pbtxt\"\n",
            "}\n",
            "\n",
            "eval_config: {\n",
            "  metrics_set: \"coco_detection_metrics\"\n",
            "  num_examples: 1101\n",
            "}\n",
            "\n",
            "eval_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/tensorflow-object-detection-faster-rcnn/data/valid/instrument.tfrecord\"\n",
            "  }\n",
            "  label_map_path: \"/content/tensorflow-object-detection-faster-rcnn/data/train/instrument_label_map.pbtxt\"\n",
            "  shuffle: false\n",
            "  num_readers: 1\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f11w0uO3jFCB"
      },
      "source": [
        "model_dir = 'training/'\n",
        "# Optionally remove content in output model directory to fresh start.\n",
        "!rm -rf {model_dir}\n",
        "os.makedirs(model_dir, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDddx2rPfex9"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tf_slim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSbFwtL_0J4f",
        "outputId": "d8fcd79d-6c56-4d7c-9b8d-cd7d7cbbaf2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tf_slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 30 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 40 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 51 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 61 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 71 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 81 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 92 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 102 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 112 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 122 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 133 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 143 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 153 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 163 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 174 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 184 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 194 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 204 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 215 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 225 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 235 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 245 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 256 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 266 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 276 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 286 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 296 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 307 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 317 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 327 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 337 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 348 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 352 kB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf_slim) (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n",
            "Installing collected packages: tf-slim\n",
            "Successfully installed tf-slim-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tf_slim as slim"
      ],
      "metadata": {
        "id": "l1iRmK780CCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lvis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lkp-EUrr0u8y",
        "outputId": "ca29f34a-184f-47dc-a78e-2ab0529ff238"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (2.8.2)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis) (4.1.2.30)\n",
            "Requirement already satisfied: pyparsing>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (3.0.7)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.21.5)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.15.0)\n",
            "Requirement already satisfied: Cython>=0.29.12 in /usr/local/lib/python3.7/dist-packages (from lvis) (0.29.28)\n",
            "Requirement already satisfied: matplotlib>=3.1.1 in /usr/local/lib/python3.7/dist-packages (from lvis) (3.2.2)\n",
            "Installing collected packages: lvis\n",
            "Successfully installed lvis-0.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lvis import results as lvis_results"
      ],
      "metadata": {
        "id": "mkNU6LaZ0tZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_io"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmE_KawS06Qf",
        "outputId": "f1b2cf4b-bcf1-4e11-f08a-0c1e08eb9471"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_io\n",
            "  Downloading tensorflow_io-0.24.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.4 MB 2.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem==0.24.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_io) (0.24.0)\n",
            "Installing collected packages: tensorflow-io\n",
            "Successfully installed tensorflow-io-0.24.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " import tensorflow_io as tfio "
      ],
      "metadata": {
        "id": "kWFFH1kI03g7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install efficientnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mG68hB7f1IVn",
        "outputId": "4e8132d2-ec48-4cf3-c4ba-f62fe03efcdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting efficientnet\n",
            "  Downloading efficientnet-1.1.1-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from efficientnet) (0.18.3)\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 2.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.21.5)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.5.2)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet) (1.4.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet) (3.2.2)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet) (2021.11.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet) (1.2.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet) (2.6.3)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet) (7.1.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet) (2.4.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (3.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (1.15.0)\n",
            "Installing collected packages: keras-applications, efficientnet\n",
            "Successfully installed efficientnet-1.1.1 keras-applications-1.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tf-models-official"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QtRpp49Q1ELN",
        "outputId": "2bbf1499-59b2-480f-e52d-c32246356a61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tf-models-official\n",
            "  Downloading tf_models_official-2.8.0-py2.py3-none-any.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 5.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (3.2.2)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (5.4.8)\n",
            "Collecting tensorflow-text~=2.8.0\n",
            "  Downloading tensorflow_text-2.8.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 27.2 MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 30.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.3.5)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (0.29.28)\n",
            "Collecting pyyaml<6.0,>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 35.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (2.0.4)\n",
            "Requirement already satisfied: tensorflow~=2.8.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (2.8.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (0.5.0)\n",
            "Requirement already satisfied: tf-slim>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.21.5)\n",
            "Collecting opencv-python-headless\n",
            "  Downloading opencv_python_headless-4.5.5.62-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 47.7 MB 3.8 MB/s \n",
            "\u001b[?25hCollecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.16.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 33.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.15.0)\n",
            "Collecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.7.1-py2.py3-none-any.whl (234 kB)\n",
            "\u001b[K     |████████████████████████████████| 234 kB 46.9 MB/s \n",
            "\u001b[?25hCollecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.12.10)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 8.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (7.1.2)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.5.12)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (4.0.1)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (4.1.3)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.4.1)\n",
            "Collecting py-cpuinfo>=3.3.0\n",
            "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
            "\u001b[K     |████████████████████████████████| 99 kB 8.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (0.12.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (3.0.1)\n",
            "Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (1.35.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (0.0.4)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (0.17.4)\n",
            "Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (1.26.3)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (21.3)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (57.4.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (2018.9)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (1.55.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (2.23.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (3.17.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official) (4.8)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official) (1.24.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official) (4.63.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official) (6.1.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official) (2021.10.8)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (3.0.7)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (2.10)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (2.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (1.0.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (1.13.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (0.24.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (0.2.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (2.8.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (1.6.3)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (0.5.3)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 31.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (2.8.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (3.1.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (13.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (3.10.0.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (1.44.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (1.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow~=2.8.0->tf-models-official) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.8.0->tf-models-official) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official) (0.4.6)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official) (4.11.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official) (3.7.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official) (3.2.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official) (0.1.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->tf-models-official) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->tf-models-official) (1.3.2)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official) (1.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official) (2019.12.20)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official) (0.8.9)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official) (1.1.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official) (2.7.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official) (0.16.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official) (21.4.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official) (1.7.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official) (0.3.4)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official) (5.4.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official) (2.3)\n",
            "Building wheels for collected packages: py-cpuinfo, seqeval\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=48ab48db9ad3ec7b391b45a42a009cdbf2320408b1748c578392cd378f5d351f\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=a6bd44c55a0e57734ae55fc166d0752e25dbb5802a1351580f3dc0a7859dd1fd\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built py-cpuinfo seqeval\n",
            "Installing collected packages: tf-estimator-nightly, portalocker, colorama, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, py-cpuinfo, opencv-python-headless, tf-models-official\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed colorama-0.4.4 opencv-python-headless-4.5.5.62 portalocker-2.4.0 py-cpuinfo-8.0.0 pyyaml-5.4.1 sacrebleu-2.0.0 sentencepiece-0.1.96 seqeval-1.2.2 tensorflow-addons-0.16.1 tensorflow-model-optimization-0.7.1 tensorflow-text-2.8.1 tf-estimator-nightly-2.8.0.dev2021122109 tf-models-official-2.8.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cv2"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade opencv-contrib-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "wadH1km42Qfk",
        "outputId": "0c7083a1-1003-4397-9eb6-52f72e8e043f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Collecting opencv-contrib-python\n",
            "  Downloading opencv_contrib_python-4.5.5.62-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (66.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 66.6 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-contrib-python) (1.21.5)\n",
            "Installing collected packages: opencv-contrib-python\n",
            "  Attempting uninstall: opencv-contrib-python\n",
            "    Found existing installation: opencv-contrib-python 4.1.2.30\n",
            "    Uninstalling opencv-contrib-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-contrib-python-4.1.2.30\n",
            "Successfully installed opencv-contrib-python-4.5.5.62\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cv2"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjDHjhKQofT5",
        "outputId": "a5fa741a-eeff-4791-f47c-94830fb8c544",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python /content/models/research/object_detection/model_main.py \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --num_eval_steps={num_eval_steps}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W0308 00:15:36.056540 140123793282944 model_lib.py:841] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 10000\n",
            "I0308 00:15:36.056875 140123793282944 config_util.py:552] Maybe overwriting train_steps: 10000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0308 00:15:36.057062 140123793282944 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "I0308 00:15:36.057236 140123793282944 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I0308 00:15:36.057465 140123793282944 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0308 00:15:36.057772 140123793282944 model_lib.py:857] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
            "I0308 00:15:36.057988 140123793282944 model_lib.py:894] create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "I0308 00:15:36.058659 140123793282944 estimator.py:202] Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f7071d083b0>) includes params argument, but params are not passed to Estimator.\n",
            "W0308 00:15:36.059234 140123793282944 model_fn.py:626] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f7071d083b0>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "I0308 00:15:36.059908 140123793282944 estimator_training.py:182] Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "I0308 00:15:36.060262 140123793282944 training.py:644] Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "I0308 00:15:36.060736 140123793282944 training.py:732] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/training_util.py:397: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0308 00:15:36.067378 140123793282944 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/training_util.py:397: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/models/research/object_detection/model_main.py\", line 108, in <module>\n",
            "    tf.app.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/platform/app.py\", line 36, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 312, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 258, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/content/models/research/object_detection/model_main.py\", line 104, in main\n",
            "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 504, in train_and_evaluate\n",
            "    return executor.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 645, in run\n",
            "    return self.run_local()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 746, in run_local\n",
            "    saving_listeners=saving_listeners)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 360, in train\n",
            "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1186, in _train_model\n",
            "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1212, in _train_model_default\n",
            "    self._get_features_and_labels_from_input_fn(input_fn, ModeKeys.TRAIN))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1048, in _get_features_and_labels_from_input_fn\n",
            "    self._call_input_fn(input_fn, mode))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1141, in _call_input_fn\n",
            "    return input_fn(**kwargs)\n",
            "  File \"/content/models/research/object_detection/inputs.py\", line 764, in _train_input_fn\n",
            "    params=params)\n",
            "  File \"/content/models/research/object_detection/inputs.py\", line 857, in train_input\n",
            "    model_config, is_training=True).preprocess\n",
            "  File \"/content/models/research/object_detection/builders/model_builder.py\", line 1250, in build\n",
            "    add_summaries)\n",
            "  File \"/content/models/research/object_detection/builders/model_builder.py\", line 606, in _build_faster_rcnn_model\n",
            "    _check_feature_extractor_exists(frcnn_config.feature_extractor.type)\n",
            "  File \"/content/models/research/object_detection/builders/model_builder.py\", line 268, in _check_feature_extractor_exists\n",
            "    'Tensorflow'.format(feature_extractor_type))\n",
            "ValueError: faster_rcnn_inception_v2 is not supported. See `model_builder.py` for features extractors compatible with different versions of Tensorflow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KP-tUdtnRybs"
      },
      "source": [
        "!ls {model_dir}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmSESMetj1sa"
      },
      "source": [
        "## Exporting a Trained Inference Graph\n",
        "Once your training job is complete, you need to extract the newly trained inference graph, which will be later used to perform the object detection. This can be done as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHoP90pUyKSq",
        "outputId": "d40e090d-e1a6-432b-aab8-f4e153fa3a81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "\n",
        "output_directory = './fine_tuned_model'\n",
        "\n",
        "lst = os.listdir(model_dir)\n",
        "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
        "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
        "last_model = lst[steps.argmax()].replace('.meta', '')\n",
        "\n",
        "last_model_path = os.path.join(model_dir, last_model)\n",
        "print(last_model_path)\n",
        "!python /content/models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --output_directory={output_directory} \\\n",
        "    --trained_checkpoint_prefix={last_model_path}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-9b78029e7230>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mlst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlst\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'model.ckpt-'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'.meta'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\d+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlst\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mlast_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.meta'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mlast_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: attempt to get argmax of an empty sequence"
          ]
        }
      ]
    }
  ]
}