{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLO_CV.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SibaIssa/Surgical-Instrument-tracking/blob/main/YOLO_CV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYma75emoV5V",
        "outputId": "348447f9-df51-4ff2-8eea-17ce495ad563"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 10946, done.\u001b[K\n",
            "remote: Total 10946 (delta 0), reused 0 (delta 0), pack-reused 10946\u001b[K\n",
            "Receiving objects: 100% (10946/10946), 11.04 MiB | 13.54 MiB/s, done.\n",
            "Resolving deltas: 100% (7563/7563), done.\n",
            "/content/yolov5\n",
            "\u001b[K     |████████████████████████████████| 596 kB 4.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 6.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 67 kB 5.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 145 kB 61.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 138 kB 56.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 178 kB 60.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[?25h  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 4.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 56.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 38.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.6 MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt # install dependencies\n",
        "%pip install -q roboflow\n",
        "%pip install -q wandb\n",
        "import torch\n",
        "import os\n",
        "from roboflow import Roboflow\n",
        "import wandb\n",
        "from IPython.display import Image, clear_output  # to display images"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# when you finish y\n",
        "rf = Roboflow(api_key=\"jvED4o1opiyLOGXmoxgg\")\n",
        "project = rf.workspace(\"new-workspace-wbivm\").project(\"cv-project-ni8w5\")\n",
        "dataset = project.version(1).download(\"yolov5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCBeoPjCoYt0",
        "outputId": "322b8747-78e0-43e4-b7e1-0a6d8da07923"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Downloading Dataset Version Zip in CV-Project-1 to yolov5pytorch: 100% [65496902 / 65496902] bytes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to CV-Project-1 in yolov5pytorch:: 100%|██████████| 2270/2270 [00:02<00:00, 833.50it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# log in to your project on Weights & Biases \n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "2UJhWxwToabD",
        "outputId": "485cc9ed-07bc-47e1-f6c4-7cda495a6220"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project=\"cv_data\", entity=\"aigerimu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "98sashoSocnE",
        "outputId": "1912a5a5-1133-4aca-c9e5-6e5499c78115"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maigerimu\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/aigerimu/cv_data/runs/2se9ktiq\" target=\"_blank\">unique-eon-2</a></strong> to <a href=\"https://wandb.ai/aigerimu/cv_data\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f480efb7b50>"
            ],
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/aigerimu/cv_data/runs/2se9ktiq?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img 416 --batch 16 --epochs 3 --data CV-Project-1/data.yaml --weights yolov5s.pt --cache"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTdjcMgooeHG",
        "outputId": "65ffe716-f164-4682-c0d5-6d94181d95a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maigerimu\u001b[0m (use `wandb login --relogin` to force relogin)\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=CV-Project-1/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=3, batch_size=16, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v6.1-0-g3752807 torch 1.10.0+cu111 CPU\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbreezy-sponge-1\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/aigerimu/YOLOv5\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/aigerimu/YOLOv5/runs/296f4lzn\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /content/yolov5/wandb/run-20220222_181938-296f4lzn\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
            "\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v6.1/yolov5s.pt to yolov5s.pt...\n",
            "100% 14.1M/14.1M [00:00<00:00, 17.2MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     21576  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model Summary: 270 layers, 7027720 parameters, 7027720 gradients, 15.9 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/yolov5/CV-Project-1/train/labels' images and labels...990 found, 0 missing, 10 empty, 0 corrupt: 100% 990/990 [00:00<00:00, 1616.25it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolov5/CV-Project-1/train/labels.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.3GB ram): 100% 990/990 [00:04<00:00, 238.27it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/yolov5/CV-Project-1/valid/labels' images and labels...88 found, 0 missing, 0 empty, 0 corrupt: 100% 88/88 [00:00<00:00, 839.03it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolov5/CV-Project-1/valid/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram): 100% 88/88 [00:00<00:00, 133.88it/s]\n",
            "Plotting labels to runs/train/exp/labels.jpg... \n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.41 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp\u001b[0m\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       0/2        0G   0.09141   0.02434   0.03922        35       416: 100% 62/62 [10:07<00:00,  9.80s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:16<00:00,  5.59s/it]\n",
            "                 all         88         88      0.116      0.193     0.0724     0.0315\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       1/2        0G   0.06359   0.02829   0.03736        44       416: 100% 62/62 [10:21<00:00, 10.02s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:18<00:00,  6.20s/it]\n",
            "                 all         88         88      0.337       0.42      0.324      0.182\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "       2/2        0G   0.05207    0.0265   0.03536        48       416:  31% 19/62 [03:13<07:15, 10.12s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights runs/train/exp/weights/best.pt --img 416 --conf 0.1 --source {dataset.location}/test/images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMkEOsjLqrnf",
        "outputId": "69632069-fb86-4746-8bca-38c54f85e718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/exp/weights/best.pt'], source=/content/yolov5/CV-Project-1/test/images, data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.1, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
            "YOLOv5 🚀 v6.1-0-g3752807 torch 1.10.0+cu111 CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 213 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n",
            "image 1/51 /content/yolov5/CV-Project-1/test/images/c_12_v_56696_f_101_jpg.rf.a27382241f4a96d3e17a2ba2355eece5.jpg: 416x384 1 tool 1, 1 tool 3, Done. (0.185s)\n",
            "image 2/51 /content/yolov5/CV-Project-1/test/images/c_12_v_56696_f_101_jpg.rf.ff8cbeb5c80de2a65197dc61314fbe5b.jpg: 160x416 1 tool 3, Done. (0.083s)\n",
            "image 3/51 /content/yolov5/CV-Project-1/test/images/c_12_v_56696_f_1076_jpg.rf.6f4436f24bc0a04b778f067ca363a580.jpg: 96x416 1 tool 3, Done. (0.056s)\n",
            "image 4/51 /content/yolov5/CV-Project-1/test/images/c_12_v_56696_f_1076_jpg.rf.e89da7bc37cb225a0f2f35b61a35d476.jpg: 352x416 1 tool 1, 1 tool 3, Done. (0.171s)\n",
            "image 5/51 /content/yolov5/CV-Project-1/test/images/c_12_v_56696_f_1151_jpg.rf.33b4f56a2d55218d7661e4f96d8ebe42.jpg: 256x416 1 tool 1, 1 tool 3, Done. (0.130s)\n",
            "image 6/51 /content/yolov5/CV-Project-1/test/images/c_12_v_56696_f_1151_jpg.rf.8dff62fe94a329d11d19f093af284f2d.jpg: 128x416 1 tool 3, Done. (0.072s)\n",
            "image 7/51 /content/yolov5/CV-Project-1/test/images/c_12_v_56696_f_1251_jpg.rf.01f753d1e7ee1585d09e1455a2868b1a.jpg: 128x416 1 tool 1, 1 tool 3, Done. (0.068s)\n",
            "image 8/51 /content/yolov5/CV-Project-1/test/images/c_12_v_56696_f_1251_jpg.rf.525076a885ff299c644ae5741a55de53.jpg: 224x416 2 tool 1s, 2 tool 3s, Done. (0.115s)\n",
            "image 9/51 /content/yolov5/CV-Project-1/test/images/c_12_v_56696_f_1251_jpg.rf.6386d6e559f8d8b8b2f4d5fe64d6bbc0.jpg: 416x352 1 tool 1, 1 tool 3, Done. (0.180s)\n",
            "image 10/51 /content/yolov5/CV-Project-1/test/images/c_12_v_56696_f_126_jpg.rf.93c558109f4bd902938d4335b8cf0396.jpg: 416x416 2 tool 1s, 1 tool 3, Done. (0.194s)\n",
            "image 11/51 /content/yolov5/CV-Project-1/test/images/c_12_v_56696_f_126_jpg.rf.de1c12f48715c7b801e40da15fa5eb91.jpg: 160x416 1 tool 1, 1 tool 3, Done. (0.077s)\n",
            "image 12/51 /content/yolov5/CV-Project-1/test/images/c_12_v_56696_f_1301_jpg.rf.5960afd4df439cf35ffa81cd7ed85550.jpg: 128x416 1 tool 1, 1 tool 2, 1 tool 3, Done. (0.073s)\n",
            "image 13/51 /content/yolov5/CV-Project-1/test/images/c_12_v_56696_f_1301_jpg.rf.70f14c19ea7d053bd660bf16ce199e17.jpg: 160x416 1 tool 1, 1 tool 2, 1 tool 3, Done. (0.152s)\n",
            "image 14/51 /content/yolov5/CV-Project-1/test/images/c_12_v_56696_f_1426_jpg.rf.0766bee0b08083f478fa5d566878c060.jpg: 128x416 1 tool 3, Done. (0.109s)\n",
            "image 15/51 /content/yolov5/CV-Project-1/test/images/c_12_v_56696_f_1426_jpg.rf.79315587bf01bfb083ddba2e5e12c895.jpg: 224x416 1 tool 1, 1 tool 3, Done. (0.182s)\n",
            "image 16/51 /content/yolov5/CV-Project-1/test/images/c_12_v_56696_f_1851_jpg.rf.86763da2adc6050dfba34a7356497f63.jpg: 96x416 2 tool 3s, Done. (0.079s)\n",
            "image 17/51 /content/yolov5/CV-Project-1/test/images/c_12_v_56696_f_1851_jpg.rf.abf2be1ac8ddbe3e44a5e7f2b8b96269.jpg: 320x416 2 tool 1s, 1 tool 3, Done. (0.262s)\n",
            "image 18/51 /content/yolov5/CV-Project-1/test/images/c_12_v_56696_f_2651_jpg.rf.b626989d5a8bf86fd0877b782fcc3e05.jpg: 192x416 1 tool 1, 1 tool 3, Done. (0.177s)\n",
            "image 19/51 /content/yolov5/CV-Project-1/test/images/c_12_v_56696_f_2651_jpg.rf.f32dcc36f269519ba7b64b1fb55fa782.jpg: 416x352 2 tool 1s, 1 tool 3, Done. (0.372s)\n",
            "image 20/51 /content/yolov5/CV-Project-1/test/images/c_12_v_56696_f_3026_jpg.rf.4a5b5dbdf614b99bfcdefea9062478f6.jpg: 256x416 1 tool 1, Done. (0.234s)\n",
            "image 21/51 /content/yolov5/CV-Project-1/test/images/c_12_v_56696_f_3026_jpg.rf.a8e390f7c26929823cfdcffcab6f7818.jpg: 416x288 1 tool 1, 1 tool 2, Done. (0.271s)\n",
            "image 22/51 /content/yolov5/CV-Project-1/test/images/c_12_v_56696_f_3026_jpg.rf.e91d5d459497de827db070fccc4384d2.jpg: 416x384 1 tool 1, 1 tool 2, 1 tool 3, Done. (0.303s)\n",
            "image 23/51 /content/yolov5/CV-Project-1/test/images/c_12_v_56696_f_3076_jpg.rf.686ed53079d931c185092ecebb2d04d7.jpg: 224x416 1 tool 1, 1 tool 3, Done. (0.289s)\n",
            "image 24/51 /content/yolov5/CV-Project-1/test/images/c_12_v_56696_f_3076_jpg.rf.d4d237d4597451e653ce7551bf8683b9.jpg: 416x256 1 tool 1, 1 tool 3, Done. (0.235s)\n",
            "image 25/51 /content/yolov5/CV-Project-1/test/images/c_12_v_56696_f_401_jpg.rf.275b92ac4b5cdc53604c5f444b1ba79c.jpg: 352x416 1 tool 1, 2 tool 3s, Done. (0.359s)\n",
            "image 26/51 /content/yolov5/CV-Project-1/test/images/c_12_v_56696_f_401_jpg.rf.b7bbd31ce9cedec0db0f5fed20033025.jpg: 128x416 1 tool 1, 1 tool 3, Done. (0.090s)\n",
            "image 27/51 /content/yolov5/CV-Project-1/test/images/c_12_v_56696_f_551_jpg.rf.60ef0a2523e1c3f3a217622e4db95e0a.jpg: 256x416 2 tool 1s, 1 tool 3, Done. (0.194s)\n",
            "image 28/51 /content/yolov5/CV-Project-1/test/images/c_12_v_56696_f_551_jpg.rf.7203d5e2b579c81b33466364fe845853.jpg: 224x416 2 tool 1s, 1 tool 3, Done. (0.160s)\n",
            "image 29/51 /content/yolov5/CV-Project-1/test/images/c_12_v_56696_f_576_jpg.rf.72911eb9fec2b871c1e7739ea8089c33.jpg: 192x416 1 tool 1, 1 tool 3, Done. (0.139s)\n",
            "image 30/51 /content/yolov5/CV-Project-1/test/images/c_12_v_56696_f_576_jpg.rf.87a77e9a4bb58bcf4113f19f908c8090.jpg: 416x256 1 tool 1, 1 tool 3, Done. (0.183s)\n",
            "image 31/51 /content/yolov5/CV-Project-1/test/images/c_12_v_56696_f_576_jpg.rf.e3338dd325f476fd608667010e286f06.jpg: 192x416 1 tool 1, 1 tool 3, Done. (0.137s)\n",
            "image 32/51 /content/yolov5/CV-Project-1/test/images/c_12_v_56696_f_851_jpg.rf.c8e69a4ad19f27be4bfc477592c5e5a1.jpg: 96x416 1 tool 3, Done. (0.096s)\n",
            "image 33/51 /content/yolov5/CV-Project-1/test/images/c_12_v_56696_f_851_jpg.rf.ee0e15e773e4442020313f1800d79718.jpg: 352x416 1 tool 1, 1 tool 3, Done. (0.408s)\n",
            "image 34/51 /content/yolov5/CV-Project-1/test/images/c_12_v_56696_f_976_jpg.rf.b6aa9bd27197909613be4650e95e5451.jpg: 128x416 1 tool 1, 1 tool 3, Done. (0.105s)\n",
            "image 35/51 /content/yolov5/CV-Project-1/test/images/c_12_v_56696_f_976_jpg.rf.f4464c6ef153300d74f8b113d293d22c.jpg: 352x416 1 tool 1, 1 tool 3, Done. (0.294s)\n",
            "image 36/51 /content/yolov5/CV-Project-1/test/images/c_13_v_23441_f_1427_jpg.rf.bf32285df912b11b235c20c392a9c194.jpg: 224x416 1 tool 3, Done. (0.172s)\n",
            "image 37/51 /content/yolov5/CV-Project-1/test/images/c_13_v_23441_f_577_jpg.rf.4c08a144b5e6d424f805855aa15c190d.jpg: 416x256 1 tool 1, 1 tool 3, Done. (0.419s)\n",
            "image 38/51 /content/yolov5/CV-Project-1/test/images/c_13_v_23441_f_577_jpg.rf.ef3a872682699876ce2085c84fd94889.jpg: 96x416 1 tool 1, 3 tool 3s, Done. (0.056s)\n",
            "image 39/51 /content/yolov5/CV-Project-1/test/images/c_13_v_23441_f_577_jpg.rf.f5f11f48bd4f129c0eadd0f136541377.jpg: 416x224 1 tool 1, 1 tool 2, Done. (0.111s)\n",
            "image 40/51 /content/yolov5/CV-Project-1/test/images/c_13_v_23441_f_602_jpg.rf.2ca07ea66f9034cf49a3f3a09d4d0ac3.jpg: 96x416 1 tool 1, 1 tool 3, Done. (0.052s)\n",
            "image 41/51 /content/yolov5/CV-Project-1/test/images/c_13_v_23441_f_602_jpg.rf.ad12f34cd31c6f416f45a3aecc886977.jpg: 416x192 3 tool 1s, 1 tool 2, Done. (0.099s)\n",
            "image 42/51 /content/yolov5/CV-Project-1/test/images/c_13_v_23441_f_602_jpg.rf.ebe460ef556ff9769ebf3842a8f2ac4c.jpg: 416x320 1 tool 1, 1 tool 2, Done. (0.149s)\n",
            "image 43/51 /content/yolov5/CV-Project-1/test/images/c_13_v_23441_f_677_jpg.rf.29df714edcdaae69954490dbb3584eaf.jpg: 416x160 1 tool 1, 1 tool 2, Done. (0.083s)\n",
            "image 44/51 /content/yolov5/CV-Project-1/test/images/c_13_v_23441_f_677_jpg.rf.3e0545625b551864a31b745b19a522fd.jpg: 416x416 1 tool 1, 1 tool 3, Done. (0.201s)\n",
            "image 45/51 /content/yolov5/CV-Project-1/test/images/c_13_v_23441_f_677_jpg.rf.9860afbac6d03ea9559e2877b6220120.jpg: 96x416 1 tool 1, 1 tool 3, Done. (0.051s)\n",
            "image 46/51 /content/yolov5/CV-Project-1/test/images/c_13_v_23441_f_702_jpg.rf.39cc97c12d43d9569940e1455ab03a00.jpg: 96x416 1 tool 1, 1 tool 2, 1 tool 3, Done. (0.049s)\n",
            "image 47/51 /content/yolov5/CV-Project-1/test/images/c_13_v_23441_f_702_jpg.rf.962ceabca685d5ffe7f812addfdf5e20.jpg: 416x160 1 tool 1, Done. (0.078s)\n",
            "image 48/51 /content/yolov5/CV-Project-1/test/images/c_13_v_23441_f_702_jpg.rf.a396aa34207b9d2c5d3239e6116b76b0.jpg: 416x384 1 tool 1, 1 tool 3, Done. (0.174s)\n",
            "image 49/51 /content/yolov5/CV-Project-1/test/images/c_13_v_23441_f_802_jpg.rf.5ce4989b029a1c553ffb162be560075c.jpg: 256x416 1 tool 1, 1 tool 3, Done. (0.113s)\n",
            "image 50/51 /content/yolov5/CV-Project-1/test/images/c_13_v_23441_f_802_jpg.rf.850984863a417f7e19556a5dc568ff13.jpg: 416x128 Done. (0.070s)\n",
            "image 51/51 /content/yolov5/CV-Project-1/test/images/c_13_v_23441_f_802_jpg.rf.bbb3e95ec5bc001cb6e8e96f29f9e649.jpg: 352x416 1 tool 1, 1 tool 2, 1 tool 3, Done. (0.164s)\n",
            "Speed: 0.9ms pre-process, 162.2ms inference, 1.1ms NMS per image at shape (1, 3, 416, 416)\n",
            "Results saved to \u001b[1mruns/detect/exp2\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}